{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9a6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Load vectorizer\n",
    "with open(\"../models/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Load best model (SVM)\n",
    "with open(\"../models/SVM.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edc97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_resume_category(resume_text):\n",
    "    cleaned_text = resume_text.lower()\n",
    "    X_input = vectorizer.transform([cleaned_text])\n",
    "    prediction = model.predict(X_input)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ebafd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reactjs Resumes'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_resume = \"\"\"\n",
    "Experienced React developer with strong knowledge of JavaScript,\n",
    "HTML, CSS, React Hooks, Redux, REST APIs, and frontend optimization.\n",
    "\"\"\"\n",
    "\n",
    "predict_resume_category(sample_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e731e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dhanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dhanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Dhanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.data_loader import extract_text\n",
    "from src.nlp.text_cleaning import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb3d96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ExcelR\\Resume_Classification_Project\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b5878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "resume_path = r\"D:\\ExcelR\\Resume_Classification_Project\\Data\\sample_resume\\sample_resume.pdf\"\n",
    "\n",
    "import os\n",
    "print(os.path.exists(resume_path))  # should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e55e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root so src/ can be found\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_loader import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c1324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 8853\n",
      "CURRICULUM VITAE\n",
      "Anjani Objective\n",
      "Priyadarshini To acquire a position in a company that would allow me to be creative and keep me\n",
      "challenged with various web projects that require employing the latest trends and\n",
      "Sr. Web Developer / React technologies.\n",
      "Employing my passion on a multitude of design wo\n"
     ]
    }
   ],
   "source": [
    "raw_text = extract_text(resume_path)\n",
    "\n",
    "print(\"Text length:\", len(raw_text))\n",
    "print(raw_text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db13f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not raw_text.strip():\n",
    "    raise ValueError(\"Resume text extraction failed. Check file path or format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d631bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "with open(\"../models/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "print(\"Vectorizer loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acef4ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer & model loaded\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "with open(\"../models/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "with open(\"../models/SVM.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(\"Vectorizer & model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85da8d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Resume Category: React Resumes\n"
     ]
    }
   ],
   "source": [
    "raw_text = extract_text(resume_path)\n",
    "\n",
    "if not raw_text.strip():\n",
    "    raise ValueError(\"Resume text extraction failed\")\n",
    "\n",
    "from src.nlp.text_cleaning import clean_text\n",
    "cleaned_text = clean_text(raw_text)\n",
    "\n",
    "X_input = vectorizer.transform([cleaned_text])\n",
    "prediction = model.predict(X_input)\n",
    "\n",
    "print(\"Predicted Resume Category:\", prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52efe9b",
   "metadata": {},
   "source": [
    "“The model predicted ‘Reactjs Resumes’ because the resume text contains React-specific keywords such as ReactJS, hooks, and frontend components, which strongly match patterns learned during training.”\n",
    "\n",
    "What’s the difference between React and ReactJS resumes?\n",
    "They are closely related roles, and some overlap is expected. The model differentiates them based on frequency and contextual usage of specific ReactJS terms in the training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
